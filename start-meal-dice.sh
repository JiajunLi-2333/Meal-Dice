#!/bin/bash
# å¿«é€Ÿå¯åŠ¨è„šæœ¬ - ç¡®ä¿ç«¯å£åŒ¹é…

echo "ğŸ”§ Starting Meal Dice with correct Ollama configuration..."

# æ£€æŸ¥Ollamaæ˜¯å¦åœ¨11435ç«¯å£è¿è¡Œ
echo "ğŸ” Checking Ollama on port 11435..."
if curl -s http://localhost:11435/api/version > /dev/null; then
    echo "âœ… Ollama is running on port 11435"
    
    # æ£€æŸ¥æ¨¡å‹
    echo "ğŸ“š Checking llama3.2:3b model..."
    if OLLAMA_HOST=localhost:11435 ollama list | grep -q "llama3.2:3b"; then
        echo "âœ… llama3.2:3b model is available"
        
        # è®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡å¹¶å¯åŠ¨æœåŠ¡å™¨
        echo "ğŸš€ Starting Node.js server with OLLAMA_PORT=11435..."
        export OLLAMA_PORT=11435
        npm run server
        
    else
        echo "âŒ llama3.2:3b model not found"
        echo "ğŸ’¡ Please download it: OLLAMA_HOST=localhost:11435 ollama pull llama3.2:3b"
        exit 1
    fi
    
else
    echo "âŒ Ollama is not running on port 11435"
    echo "ğŸ’¡ Please start Ollama: OLLAMA_HOST=localhost:11435 ollama serve"
    exit 1
fi
